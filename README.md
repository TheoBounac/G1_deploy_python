 <p align="center">
  <img src="doc/im2.png" width="1000">
  <br>
 </p>
 
# <h2 align="center">G1 RL Deploy Python</h2>

**This repository provides a Python deployment framework for the Unitree G1 humanoid robot, designed to run reinforcement-learning policies both in simulation and on real hardware.**
**It supports SIM-to-SIM deployment in MuJoCo as well as SIM-to-REAL execution on the physical G1 robot, with a focus on UI control and safety during deployment.**

**It deploys RL policies trained for locomotion and teleoperated whole-body control.**


<table align="center" style="border-collapse:collapse;">
<th style="width:50%; text-align:center;">
  <div style="display:inline-block; width:200px;">Deploy on Mujoco</div>
</th>

  <tr>
    <td style="width:50%; text-align:center;">
      <img src="doc/gif3.gif" style="width:100%; display:block; margin:auto;">
    </td>

  </tr>
</table>


---
## Project overview

This project implements a complete deployment guide:

 - ğŸ® How to deploy Reinforcement Learning (RL) policies in **Mujoco**

 - ğŸ¤– How to deploy models on the **real G1 robot** via  Unitree SDK

Reinforcement Learning models are trained with : [unitree_rl_lab](https://github.com/unitreerobotics/unitree_rl_lab) for Locomotion, and [TWIST](https://github.com/YanjieZe/TWIST) for Teleoperated Whole-Body Control. 

The project combines **Python + Unitree SDK + Mujoco + IsaacLab + Unitree_rl_lab + Twist**, enabling the deployment of RL policies to the real robot with an Interactive **UI** and **Safety measures**.

---
## ğŸ“ Architecture

```
G1_deploy_python/
â”œâ”€â”€ main.py
â”œâ”€â”€ controller/
â”‚   â”œâ”€â”€ buttons.py
â”‚   â”œâ”€â”€ controller.py
â”‚   â”œâ”€â”€ security.py
â”‚   â”œâ”€â”€ server_high_level_motion_lib.py
â”‚   â””â”€â”€ UI.py
â”œâ”€â”€ states/
â”‚   â”œâ”€â”€ fsm.py
â”‚   â”œâ”€â”€ base_state.py
â”‚   â”œâ”€â”€ state_passive.py
â”‚   â”œâ”€â”€ state_default_static.py
â”‚   â”œâ”€â”€ state_velocity.py
â”‚   â”œâ”€â”€ state_mocap.py
â”‚   â””â”€â”€ emergency.py
â”œâ”€â”€ policies/
â”‚   â””â”€â”€ locomotion_policies/
â”‚   â””â”€â”€ mimici_policies/
â”œâ”€â”€ doc/
â”œâ”€â”€ common/
â””â”€â”€ assets/
```

---
## âš™ï¸ System Requirements

|  Component |  Recommended Version |
|--------------|------------------------|
| Go2 robot (Unitree) | Edu version with feet sensors |
| **Ubuntu** | 22.04 LTS |
| **Python** | 3.10+ |
| **ROS 2** | Humble |
| **Isaac Sim / Isaac Lab** | 4.0.0+ |
| **CUDA** | 11.8+ |
---

---
<h2 align="center">ğŸ”§ Installation GuidesğŸ”§</h2> 
As mentioned earlier, this project is divided into two main parts :

  1. Training a reinforcement learning (RL) model in IsaacLab
  3. Deploying the trained model on the real Unitree Go2 robot
     
 I strongly suggest you to follow **Part 1** then **Part 2**. If you only want to deploy an RL model, you can skip the IsaacLab training tutorial. However, make sure to use the provided model, as it follows a specific observation structure required for deployment.

**Part 1** : [ğŸ“˜ How to train Reinforcement Learning (RL) policies on **IsaacLab Simulation**](doc/Isaaclab.md)

**Part 2** : [ğŸ“˜ How to **deploy models on the real Go2 robot** via the Unitree SDK](doc/Deploy.md)

Full tutorial for kalman filter from Inria Paris :

[ğŸ“˜ How to use  **Kalman filter (Inria Paris)** for real-time control and sensor/command integration](doc/Deploy_with_Kalman_filter.md)


---

##  Links

These are the repositories I used for my project :

| ğŸ”— Resources | ğŸ“ Link |
|--------------|---------|
|  **IsaacLab (NVIDIA)** | [https://github.com/isaac-sim/IsaacLab](https://github.com/isaac-sim/IsaacLab) |
|  **Unitree SDK2 Python** | [https://github.com/unitreerobotics/unitree_sdk2_python](https://github.com/unitreerobotics/unitree_sdk2_python) |
|  **unitree_rl_lab** | [https://github.com/unitreerobotics/unitree_rl_lab](https://github.com/unitreerobotics/unitree_rl_lab) |
|  **TWIST** | [https://github.com/YanjieZe/TWIST](https://github.com/YanjieZe/TWIST) |




---

## ğŸ‘¥ Author & Contributors

**Author:**  
ThÃ©o Bounaceur  
Laboratory **LORIA** (CNRS / University of Lorraine), Nancy, France  
ğŸ§¬ Field: Reinforcement Learning Â· Unitree robots Â· IsaacLab Â· IsaacGym Â· ROS 2 Â· Unitree SDK2  
ğŸ“« Contact: theo.bounaceur@loria.fr  

**Supervisors / Advisors:**  
- Adrien Guenard  
- Cyril Regan  
